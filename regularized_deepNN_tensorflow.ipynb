{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "TSPse",
      "launcher_item_id": "24mxX"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "regularized_deepNN_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianbuendia1/DeepLearning-/blob/main/regularized_deepNN_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQInL2R-rxRP"
      },
      "source": [
        "# Image Application: cat or not?\n",
        "\n",
        "**After this assignment you will be able to:**\n",
        "- Build and apply a deep neural network to supervised learning. \n",
        "- Learn how to do data normalization\n",
        "- learn how to do weight initialization\n",
        "- Learn how to use regularization\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xys4aQ5UrxRT"
      },
      "source": [
        "## 1 - Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hei_-Ma-tOhR"
      },
      "source": [
        "**Exercise**: Please mount your Google drive, and set up your working folder here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0U8Y54Congl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7bbd16-389a-4009-ca22-fc47ad421c1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibN88sy3sxy5"
      },
      "source": [
        "import os\n",
        "# start your code here\n",
        "os.chdir(\"/content/drive/My Drive/DeepLearning/Homework4/regularization_tf\") # change your working folder here\n",
        "# end your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9H7MX-2rxRT"
      },
      "source": [
        "Let's first import all the packages that you will need during this assignment. \n",
        "- [numpy](https://www.numpy.org/) is the fundamental package for scientific computing with Python.\n",
        "- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n",
        "- [h5py](http://www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n",
        "- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) are used here to test your model with your own picture at the end.\n",
        "- dnn_app_utils provides the customized functions that will be used in this notebook.\n",
        "- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY54vu0IrxRU"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import dnn_app_utils_v3 as du\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "\n",
        "# refresh 'planar_utils' module\n",
        "import imp\n",
        "imp.reload(du)\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng-fWoBBrxRW"
      },
      "source": [
        "## 2 - Dataset\n",
        "\n",
        "**Problem Statement**: You are given a dataset (\"data.h5\") containing:\n",
        "    - a training set of m_train images labelled as cat (1) or non-cat (0)\n",
        "    - a test set of m_test images labelled as cat and non-cat\n",
        "    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).\n",
        "\n",
        "Let's get more familiar with the dataset. Load the data by running the cell below.\n",
        "\n",
        "The training input and output are stored in 'train_x_orig' and 'train_y'. The test input and output are stored in 'test_x_orig' and 'test_y'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeriZ2MHrxRW"
      },
      "source": [
        "train_x_orig, train_y, test_x_orig, test_y, classes = du.load_data()\n",
        "#print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6gdY7eWrxRX"
      },
      "source": [
        "The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC4JfABrxRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "46394f77-9f78-406a-b993-8feec9c69c17"
      },
      "source": [
        "# Example of a picture\n",
        "index = 0\n",
        "plt.imshow(train_x_orig[index])\n",
        "print(\"y = \" + str(train_y[index,0]) + \". It's a \" + classes[train_y[index,0]].decode(\"utf-8\") +  \" picture.\")\n",
        "#print(train_x_orig[index].shape,train_x_orig[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = 0. It's a non-cat picture.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LcmDz99lbsD"
      },
      "source": [
        "Let's explore more about the training data. We are curious about the shape of each image and can use 'train_x_orig[index].shape' to expore it. \n",
        "**Exercise**: Can you tell what the pixel number of each image is?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKIwmFCyrxRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64747373-2939-42af-f320-c43017fa30b9"
      },
      "source": [
        "# Explore your dataset \n",
        "image_shape=train_x_orig[index].shape\n",
        "print(\"Each image is of size: \", image_shape)\n",
        "#start your code here\n",
        "num_px=205   # the number of pixels in each column of the image. Hint: The 1st element in image_shape indicates this number?\n",
        "#end your code here\n",
        "print('Number of pixels in each column of the image:', num_px)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each image is of size:  (64, 64, 3)\n",
            "Number of pixels in each column of the image: 205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBoQZoWQpBU4"
      },
      "source": [
        "We just take a close look at an image of the image set. Now, let's take a look at the whole training set. \n",
        "\n",
        "**Exercise**: The first 4 lines in the following cell print out the shape of the trining images. There are 209 images, and each image has 64 by 64 pixcels and GRB color. \n",
        "\n",
        "Please print out the shape of the test input (stored in `test_x_orig`) and output (stored in `test_y`) data, and tell how many images we have in the test data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Q7fiuYnP1C",
        "outputId": "2b833aca-fac2-4bc6-8253-60572797fb60"
      },
      "source": [
        "train_x_shape=train_x_orig.shape\n",
        "m_train = train_x_shape[0]\n",
        "print (\"train_x_orig shape: \",train_x_shape)\n",
        "print (\"Number of training examples: \" ,m_train)\n",
        "# start your code here\n",
        "test_x_shape=test_x_orig.shape \n",
        "test_y_shape=test_y.shape\n",
        "m_test =  test_x_shape[0] \n",
        "# end your code here\n",
        "\n",
        "print (\"test_x_orig shape: \" ,test_x_shape)\n",
        "print (\"test_y shape: \" , test_y_shape)\n",
        "print (\"Number of test examples: \" ,m_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x_orig shape:  (209, 64, 64, 3)\n",
            "Number of training examples:  209\n",
            "test_x_orig shape:  (50, 64, 64, 3)\n",
            "test_y shape:  (1, 50)\n",
            "Number of test examples:  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMoCSiCWrxRY"
      },
      "source": [
        "As mentioned in our lecture, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=12XXwVJpcT-moegSdzejC-W-hD79qDSk9)\n",
        "<caption><center> <u>Figure 1</u>: Image to vector conversion. <br> </center></caption>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrdXco3grxRY"
      },
      "source": [
        "# Reshape the training and test examples \n",
        "train_x_flatten = train_x_orig.reshape(train_x_shape[0], -1)   # The \"-1\" makes reshape flatten the remaining dimensions\n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvmsCTJfN_OS"
      },
      "source": [
        "Data normalization can help us accelerate the training process. The RGB values of an image are integers in the range of [0,255]. We can normalize the training images to have the feature values between 0 and 1 by using `train_x = train_x_flatten/255.0`.\n",
        "\n",
        "**Exercise**: We normalize the training images using `train_x = train_x_flatten/255.0` in the 1st line. Please normalize the test images to have feature values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpmJC7S8OlGL",
        "outputId": "dcc5fdc9-b2ff-4725-e403-82528d832db6"
      },
      "source": [
        "# Standardize data to have feature values between 0 and 1.\n",
        "train_x = train_x_flatten/255.0\n",
        "\n",
        "#start your code here\n",
        "test_x = test_x_flatten/255.0\n",
        "#end your code here\n",
        "\n",
        "print (\"train_x's shape: \" + str(train_x.shape))\n",
        "print (\"test_x's shape: \" + str(test_x.shape))\n",
        "print (\"train_y's shape: \" + str(train_y.shape))\n",
        "print (\"test_y's shape: \" + str(test_y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x's shape: (209, 12288)\n",
            "test_x's shape: (50, 12288)\n",
            "train_y's shape: (1, 209)\n",
            "test_y's shape: (1, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q-yRZNQQBtY"
      },
      "source": [
        "###3- Build your neural network ###\n",
        "Now, we are going to use the skills in the first module to build our neural network. \n",
        "\n",
        "Excep the input layer, you can use \n",
        "\n",
        "`tf.keras.layers.Dense(20,activation='relu', \n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            bias_initializer='zeros')`\n",
        "\n",
        "to build the layers. In this example, we have 20 neurons in this layer, use 'relu' as the activation function, initialize our weight randomly using 'glorot_uniform', and our bias is initialized to be 'zeros'. \n",
        "\n",
        "First, we will need an input layer. How many neurons will you need in the input layer? Hint: how many elements does every training input have?\n",
        "\n",
        "Second, we will build several hidden layers. You are free to choose the number of neurons in every hidden layer. \n",
        "\n",
        "Last, we will build the output layer. How many neurons will you need in the output layer? Which activation function is more suitale in this problem? Hint: how many elements does every training output have? What is the range of the training output?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H71UHvjaxREs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df75e8d-b655-4276-82ec-3799710f831f"
      },
      "source": [
        "tf.random.set_seed(1) # we fixed the seed of the random number generator, so every time running this code, we can have the same results.\n",
        "\n",
        "# start your code here\n",
        "cat_model=tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(12288,)), # how many elements are there in every training image?\n",
        "    tf.keras.layers.Dense(20,activation='relu', # in layer 1, we will have 20 neurons and use 'relu' as the activation function\n",
        "                            kernel_initializer='glorot_uniform', # we will randomly choose the initial weight using the 'glorot_uniform' method\n",
        "                            bias_initializer='zeros'), # we will initialize all bias to be zeros.\n",
        "    #please follow the example of layer 1 to add more hidden layers here. \n",
        "\n",
        "    # End adding hidden layers                    \n",
        "    tf.keras.layers.Dense(1,activation='sigmoid', # how many elements are there in every training output\n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            bias_initializer='zeros'),\n",
        "])\n",
        "# end your code here\n",
        "cat_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                245780    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,801\n",
            "Trainable params: 245,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRMApHybXkD8"
      },
      "source": [
        "Now, let's compile the model. When comiling your model, you will need to specify the optimizer, the loss function, and the metrics.\n",
        "\n",
        "For optimizers, the most popular ones are 'Adam' and its derivatives. You can also try 'RMSprop' and 'SGD' to see which one works better for you. You might need adjust the learning rate to acceperate the training process. \n",
        "\n",
        "For loss functions, our problem is a two-class classification problem. The most popular loss function would be 'BinaryCrossentropy'. If this is a multiple-class classification problem, you probably want to try 'CategoricalCrossentropy' or 'SparseCategoricalCrossentropy'. \n",
        "\n",
        "For the metrics, we want to know the accuracy of our model. Therefore, I would recommend 'accuracy'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2zh-VWoT7o5"
      },
      "source": [
        "# start your code here\n",
        "cat_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Optimizer. Please change 'None' to some meaningful learning rate which is usually <1\n",
        "    # Loss function to minimize\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=['accuracy'],\n",
        "                 )\n",
        "# end your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGSAcJuTZw2C"
      },
      "source": [
        "It's time to train. \n",
        "\n",
        "We can plot training history. It can help us to adjust the parameters. \n",
        "\n",
        "If the training loss increases, we may want to decrease the `learning_rate`.\n",
        "\n",
        "If the training loss has large vibration, we may want to decrease the `learning_rate`. \n",
        "\n",
        "If the training loss decreases too slowly, we need to increase `learning_rate`.\n",
        "\n",
        "If the training loss decreases at a good speed, but ends up large, we may want to increase the epoch number. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "TYZnpHLPVIRY",
        "outputId": "136ca9e0-abf0-4431-add3-6f1f55af5488"
      },
      "source": [
        "# start your code here\n",
        "history = cat_model.fit(\n",
        "    train_x, # input data\n",
        "    train_y, # real output data\n",
        "    validation_split=0.15, # this number is usually betwwen 0 and 0.3. It is the portion used as validation data, \n",
        "    epochs=10, # how many iterations do you want to train your model? Your data will be reused to train the model for the number of epochs. I trained 5 min for this model\n",
        ")\n",
        "# end your code here. \n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss','val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3ecfee106cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# real output data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# this number is usually betwwen 0 and 0.3. It is the portion used as validation data,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# how many iterations do you want to train your model? Your data will be reused to train the model for the number of epochs. I trained 5 min for this model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# end your code here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 177\n  y sizes: 1\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yLMfXSWfKVA"
      },
      "source": [
        "### 4. test ###\n",
        "Let us test their performance using our test dataset. The test dataset is never used to train the models, and reflects the acutual performance of the model when it is used in the general images.\n",
        "\n",
        "To evaluate the model , we can use\n",
        "`cat_model.evaluate(test_x,test_y)`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "4pyTS3HmHXFQ",
        "outputId": "9e775772-8c61-4e5c-9313-f5e105a1d286"
      },
      "source": [
        "cat_model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-828214f36bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 50\n  y sizes: 1\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crWckG9I807Q"
      },
      "source": [
        "The expected accuracy is higher than 0.7. If the accuracy is lower than 0.7, you may want to increase the epoch number, adjust the learning rate, and the regularizer weight, to achieve the goal. \n",
        "\n",
        "For your reference, I trained the model for 5 min to achieve that goal. \n",
        "\n",
        "If you have achieved the 0.7 goal, I would like to challenge you for the 0.8 accuracy for the test set. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5- Adding Regularization ###\n",
        "After enough training, you probably notice that while the training loss is very small, the validation loss is quite large. This is what we called **low bias high vairance** problem. We have several ways to deal with it, \n",
        "1. L1/L2 regularization, \n",
        "2. drop out, and \n",
        "3. early stop. \n",
        "\n",
        "I would recommend you try the regularization first, because it's easy to use and usually works. \n",
        "\n",
        "To add regularization to the network, we only need to specify this option in the 'Dense' layer as follows.\n",
        "\n",
        "`tf.keras.layers.Dense(20,activation='relu', \n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          bias_initializer='zeros', \n",
        "                          kernel_regularizer=tf.keras.regularizers.L2(0.01))`\n",
        "\n",
        "The parameter **kernel_regularizer=tf.keras.regularizers.L2(0.01)** says that we want an 'L2' regularizer with weight 0.01. A higher weight usually can reduce the validation loss more. But if the weight is too large, the training loss might redecus very slowly."
      ],
      "metadata": {
        "id": "U61bqEXKOFq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "cat_model_regu=tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(12288,)),\n",
        "    tf.keras.layers.Dense(20,activation='relu', # in layer 1, we will have 20 neurons and use 'relu'\n",
        "                          kernel_initializer='glorot_uniform',# we will randomly choose the initial weight using the 'glorot_uniform' method as the activation function\n",
        "                          bias_initializer='zeros', # we will initialize all bias to be zeros.\n",
        "                          kernel_regularizer=tf.keras.regularizers.L2(0.05)), # L2-regularization can be added here\n",
        "    #please feel free to add more hidden layers with regularizer\n",
        "    \n",
        "    # End adding hidden layers \n",
        "    tf.keras.layers.Dense(1,activation='sigmoid', \n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            bias_initializer='zeros', \n",
        "                            kernel_regularizer=tf.keras.regularizers.L2(0.05)),\n",
        "])\n",
        "\n",
        "cat_model_regu.summary()"
      ],
      "metadata": {
        "id": "a2yXbuObOcKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f5acf2-3c0d-4539-a89e-2d56bf5bf6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 20)                245780    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,801\n",
            "Trainable params: 245,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you can compile and train the regularized neural network as before."
      ],
      "metadata": {
        "id": "wFRAcU0oPJa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start your code here\n",
        "cat_model_regu.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Optimizer please change \"None\" to some meaningful number here\n",
        "    # Loss function to minimize\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=['accuracy'],\n",
        "                 )\n",
        "# end your code here. "
      ],
      "metadata": {
        "id": "WBDncfdhPMiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start your code here\n",
        "history_regu = cat_model_regu.fit(\n",
        "    train_x, # input data\n",
        "    train_y, # real output data\n",
        "    validation_split=0.1, # this number is usually betwwen 0 and 0.3. It is the portion used as validation data, \n",
        "    epochs=70, # how many iterations do you want to train your model? Your data will be reused to train the model for the number of epochs. I trained 5 min for this model\n",
        ")\n",
        "# end your code here\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history_regu.history['loss'])\n",
        "plt.plot(history_regu.history['val_loss'])\n",
        "plt.legend(['loss','val_loss'])"
      ],
      "metadata": {
        "id": "7ykpmUmDPWTl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "f00d5b9c-3ccf-47a3-aeab-89ab73247b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-8f13e243cd2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# real output data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# this number is usually betwwen 0 and 0.3. It is the portion used as validation data,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# how many iterations do you want to train your model? Your data will be reused to train the model for the number of epochs. I trained 5 min for this model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# end your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 188\n  y sizes: 1\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the training, we can evaluate the regularized NN use the following command. "
      ],
      "metadata": {
        "id": "1WOoKagyPudE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model_regu.evaluate(test_x,test_y)"
      ],
      "metadata": {
        "id": "YXZxD8R-P78E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected accuracy is highter than 0.8. "
      ],
      "metadata": {
        "id": "o1IED5YNP7GM"
      }
    }
  ]
}